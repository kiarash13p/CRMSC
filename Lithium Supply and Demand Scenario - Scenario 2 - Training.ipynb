{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2 - With some improvements\n",
    "\n",
    "As we witnessed some good and bad points on the previous attempt, the model `llama 2` require some training ( pre-training ) in order to provide suitable answers regarding supply chain of CRM. Thus, our idea here is to feed the model with some assumptions and Q&A, let it understand how to extract information and redesign responses more accurate. Our main assumption is that no external mathematical model is needed for purposes rather than text generation like modelling, estimating, or solving simple algebra equations.\n",
    "On this scenario, we are assuming that this model is able to predict the price of Lithium Hydroxide CIF well, given the price data from 15th of September till last day of October. We want to see the model's reaction and capability towards this request. \n",
    "\n",
    "We know that for forecasting the price, several model, most of which are based on AI, could execute this purpose accurately. Here, we want to see how close the `prediction` is to the reality.\n",
    "-   Will the model understand that no price is going to be published during weekends?\n",
    "-   Will the model realize the fact that prediction requires additional data, other than of numerical? For instance, will model request to be fed about geopolitical, vendornames, or other parameters which contribute to making disruptions in the price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub repositories\\CRMSC\\LlamaChatTraining Environment\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`AnnotionFormat` is deprecated and will be removed in v4.38. Please use `transformers.image_utils.AnnotationFormat` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\GitHub repositories\\CRMSC\\LlamaChatTraining Environment\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "bin d:\\GitHub repositories\\CRMSC\\LlamaChatTraining Environment\\Lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.dll\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub repositories\\CRMSC\\LlamaChatTraining Environment\\Lib\\site-packages\\trl\\trainer\\ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from typing import List, Optional\n",
    "import llama\n",
    "from llama import Llama, Dialog\n",
    "# import datasets # needed for handling datasets\n",
    "from datasets import (  load_dataset_builder, # finding info, description, etc.\n",
    "                        load_dataset, # Loading from our Huggingface profile\n",
    "                        )\n",
    "# import transformers\n",
    "from transformers import (\n",
    "    # LlamaForCausalLM , \n",
    "    LlamaTokenizer, # Two core modules for handling model and tokenizer\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    PreTrainedTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    get_scheduler,\n",
    "    SchedulerType,\n",
    "    AdamW,\n",
    "    training_args,\n",
    "    TrainingArguments,\n",
    "    IntervalStrategy,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    ")\n",
    "# trl stands for Transformer Reinforcement Learning\n",
    "from trl import SFTTrainer\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    "    TaskType\n",
    ")\n",
    "import evaluate\n",
    "import sys\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: read).\n",
      "Your token has been saved in your configured git credential helpers (manager).\n",
      "Your token has been saved to C:\\Users\\kpashna\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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 --add-to-git-credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='NVIDIA GeForce RTX 4090', major=8, minor=9, total_memory=24563MB, multi_processor_count=128)\n"
     ]
    }
   ],
   "source": [
    "print( torch.cuda.get_device_properties(device=0) )\n",
    "#torch.cuda.set_per_process_memory_fraction( 0.9 , 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define major elements of Llama2 7b\n",
    "os.environ['models_loc'] : str                  =       'D:\\GitHub repositories\\llama\\\\'\n",
    "os.environ['ckpt_dir']   : str                  =       os.environ['models_loc'] + 'llama-2-7b-chat' \n",
    "os.environ['tokenizer_path'] : str              =       os.environ['models_loc'] + 'tokenizer.model'\n",
    "os.environ['ckpt_dir_crmsc']   : str            =       os.environ['models_loc'] + 'llama-2-7b-chat-hf' \n",
    "os.environ['ckpt_dir_crmsc_output']   : str     =       os.environ['models_loc'] + 'llama-2-7b-chat-hf-crmsc' \n",
    "os.environ['RANK']                      =       '0'\n",
    "os.environ['WORLD_SIZE']                =       '1'\n",
    "os.environ['MASTER_ADDR']               =       'localhost'\n",
    "os.environ['MASTER_PORT']               =       '12355'\n",
    "B_INST, E_INST              =   \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS                =   \"<<SYS>>\", \"<</SYS>>\"\n",
    "PAD                         =   '[PAD]'\n",
    "\n",
    "# Use when we are going to ignore splitting\n",
    "train_dataset               =       [\n",
    "    'env_1 - converted.txt',    \n",
    "    'env_2 - converted.txt',\n",
    "    'env_3 - converted.txt',\n",
    "    # 'env_3 - converted.txt',\n",
    "    # 'env_general - converted.txt',\n",
    "    ]\n",
    "validation_dataset               =       [\n",
    "    'eenv_1 - converted.txt',\n",
    "    # 'eenv_1 - converted.txt',\n",
    "    # 'eenv_2 - converted.txt',\n",
    "    ]\n",
    "\n",
    "bnb_4bit_compute_dtype                  =       'float16' # Compute dtype for 4-bit base models\n",
    "use_4bit                                =       True # Activate 4-bit precision base model loading\n",
    "bnb_4bit_quant_type                     =       'nf4' # Quantization type (fp4 or nf4)\n",
    "use_nested_quant                        =       False # Activate nested quantization for 4-bit base models\n",
    "__cuda                                  =       torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "device_map                              =       __cuda#{\"\": 0 } # Load the entire \n",
    "lora_alpha                              =       64 \n",
    "lora_dropout                            =       0.05\n",
    "lora_r                                  =       16 # might be too much, needs to be modified later\n",
    "per_device_train_batch_size     =   3\n",
    "per_device_eval_batch_size      =   3\n",
    "gradient_accumulation_steps     =   1       #  Number of updates steps to accumulate the gradients for, before performing a backward/update pass.\n",
    "eval_accumulation_steps         =   1       #  Number of predictions steps to accumulate the output tensors for, before moving the results to the CPU.\n",
    "eval_delay                      =   0      #  Number of epochs or steps to wait for before the first evaluation can be performed\n",
    "gradient_checkpointing          =   False   # Default is false,  If True, use gradient checkpointing to save memory at the expense of slower backward pass.\n",
    "num_train_epochs                =   20\n",
    "# Optimizer\n",
    "optim                           =   training_args.OptimizerNames('paged_adamw_32bit')\n",
    "\n",
    "logging_steps                   =   1   # log every x updates steps\n",
    "learning_rate                   =   5e-4\n",
    "fp16                            =   True   #   Whether to use fp16 16-bit (mixed) precision training instead of 32-bit training.\n",
    "bf16                            =   False   #   Whether to use bf16 16-bit (mixed) precision training instead of 32-bit training\n",
    "max_grad_norm                   =   1e-4     #   Maximum gradient norm (for gradient clipping). default is 1.0\n",
    "# max_steps                       =   200      #   number of optimizer update steps / training steps to perform\n",
    "warmup_ratio                    =   0.0     #   Ratio of total training steps used for a linear warmup from 0 to learning_rate.\n",
    "warmup_steps                    =   25\n",
    "weight_decay                    =   0.0\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "lr_scheduler_type               =   SchedulerType.LINEAR\n",
    "\n",
    "group_by_length                 =   False   # Default is false\n",
    "max_seq_length                  =   512\n",
    "packing                         =   False # use packing dataset training\n",
    "evalaution_strategy             =   IntervalStrategy.STEPS\n",
    "eval_steps                      =   1\n",
    "saving_strategy                 =   IntervalStrategy.STEPS\n",
    "save_steps                      =   5  # save every x steps\n",
    "\n",
    "load_best_model_at_end          =   True\n",
    "metric_for_best_model           =   'eval_loss'\n",
    "greater_is_better               =   False\n",
    "# settings for tokenizer\n",
    "padding_side                    =   'right'\n",
    "max_length                      =   max_seq_length # this might be as same as max_seq_length, but for making a difference between trainer and tokenizer, we defined this parameter\n",
    "clean_up_tokenization_spaces    =   True # False by default\n",
    "use_default_system_prompt       =   True # False by default\n",
    "# Inhertir from Guardrail ML ( https://colab.research.google.com/drive/134o_cXcMe_lsvl15ZE_4Y75Kstepsntu?usp=sharing#scrollTo=nAMzy_0FtaUZ )\n",
    "def load_model( padding_side : str = padding_side):\n",
    "    compute_dtype   =   getattr(torch,bnb_4bit_compute_dtype) # focusing on 4 bits quantization\n",
    "    print( f\"Compute dtype is < {compute_dtype} >\")\n",
    "    bnb_config      =   BitsAndBytesConfig (\n",
    "        load_in_4bit    =   use_4bit,\n",
    "        bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "        bnb_4bit_compute_dtype=bnb_4bit_compute_dtype,\n",
    "        bnb_4bit_use_double_quant=use_nested_quant\n",
    "    )\n",
    "    \n",
    "    if compute_dtype == torch.float16 and use_4bit:\n",
    "        major , _ = torch.cuda.get_device_capability()\n",
    "        if major >= 8:\n",
    "            print( \"*\" * 20 , \"Your GPU suports bfloat16, accelerating with the argument --bfl6\" , \"=\" * 20 )\n",
    "    \n",
    "    # Initializing the model\n",
    "    model   =   AutoModelForCausalLM.from_pretrained( os.environ['ckpt_dir_crmsc'],\n",
    "                                                    device_map              =   __cuda,\n",
    "                                                    quantization_config     =   bnb_config,\n",
    "                                                      )\n",
    "    model.config.use_cache      =   False   # Whether or not the model should return the last key/values attentions\n",
    "    model.config.pretraining_tp =   1       # for faster computation, but inaccurate, increase for better accuracy but slow calculation\n",
    "\n",
    "    # Initializing Parameter-Efficient Fine-Tuning configuration (Peft)\n",
    "    # Harnessing Low-Rank approximation technique\n",
    "    peft_config     =   LoraConfig(\n",
    "        lora_alpha=lora_alpha,\n",
    "        lora_dropout=lora_dropout,\n",
    "        r=lora_r,\n",
    "        target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        # \"lm_head\",\n",
    "        ],\n",
    "        bias='none',\n",
    "        task_type=TaskType.CAUSAL_LM\n",
    "    )\n",
    "\n",
    "    # Finally, loading tokenizer\n",
    "    # we use models location instead of '.model' to avoid warning, as in new version (v5) will be deprecated, also trust argument needs to be checked later\n",
    "    tokenizer       =   LlamaTokenizer.from_pretrained( os.environ['ckpt_dir_crmsc'] , \n",
    "                                                      trust_remote_code=True,\n",
    "                                                    \n",
    "                                                      padding_side=padding_side,\n",
    "                                                      add_bos_token=False,   # bos is True by default\n",
    "                                                      add_eos_token=False,   # eos is False by default\n",
    "                                                      clean_up_tokenization_spaces  =   clean_up_tokenization_spaces, \n",
    "                                                      use_default_system_prompt     =   use_default_system_prompt,\n",
    "                                                      ) \n",
    "    # tokenizer.add_special_tokens({'pad_token': '[PAD]'}) # or 'tokenizer.eos_token\n",
    "    tokenizer.pad_token = E_INST\n",
    "    tokenizer.return_special_tokens_mask    =   True # Because of DataCollator request in help documentation\n",
    "    tokenizer.special_tokens_mask           =   \"[MASK]\"\n",
    "    return model , tokenizer , peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute dtype is < torch.float16 >\n",
      "******************** Your GPU suports bfloat16, accelerating with the argument --bfl6 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='D:\\\\GitHub repositories\\\\llama\\\\llama-2-7b-chat-hf', revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, r=16, target_modules={'up_proj', 'gate_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj'}, lora_alpha=64, lora_dropout=0.05, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={})\n",
      "trainable params: 39,976,960 || all params: 6,778,392,576 || trainable%: 0.589770503135875\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model , tokenizer , peft_config     =   load_model()\n",
    "peftmodel   =   get_peft_model(model,peft_config)\n",
    "print( peft_config )\n",
    "print( peftmodel.print_trainable_parameters() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear4bit(\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          )\n",
      "          (k_proj): Linear4bit(\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          )\n",
      "          (v_proj): Linear4bit(\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          )\n",
      "          (o_proj): Linear4bit(\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          )\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear4bit(\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=11008, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          )\n",
      "          (up_proj): Linear4bit(\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=11008, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          )\n",
      "          (down_proj): Linear4bit(\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=11008, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (base_layer): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "          )\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print( model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): LlamaForCausalLM(\n",
      "      (model): LlamaModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=11008, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=11008, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=11008, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): LlamaRMSNorm()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print( peftmodel )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Optimizer and LrScheduler\n",
    "# optimizer           =   AdamW( peftmodel.parameters() , lr = learning_rate )\n",
    "# lr_scheduler        =   get_scheduler( SchedulerType.CONSTANT_WITH_WARMUP , optimizer , num_warmup_steps=warmup_steps )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: \n",
      "Features: {'text': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "# our dataset has already been formatted to a well-shaped format, need to include padding.\n",
    "def tokenize( sample ):\n",
    "    # return tokenizer( sample['text'] , max_length=max_length , padding='max_length' )\n",
    "    return tokenizer( sample['text']  )\n",
    "# Finding some general information about dataset(s)\n",
    "dataset_builder_env         =       load_dataset_builder( \"kiarash13p/crmsc-envs\")\n",
    "# dataset_env                 =       load_dataset(\"kiarash13p/crmsc-envs\" , data_files={ 'train': train_dataset , 'validation' : validation_dataset}).shuffle(seed=42).flatten_indices()\n",
    "# do not forget to put all dicts in '[]' on huggingface if its json\n",
    "# Flattening makes the reading faster ( 10x according to website guides )\n",
    "dataset_env                 =       load_dataset(\"kiarash13p/crmsc-envs\" , split='train')\n",
    "print( f\"Description: {dataset_builder_env.info.description}\" )\n",
    "print( f\"Features: {dataset_builder_env.info.features}\" )\n",
    "\n",
    "#shuffling and selecting -> later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 81\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 27\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_env_split  = dataset_env.train_test_split( train_size=0.75 , shuffle=True , seed=list(numpy.random.randint(10,399,len(dataset_env))))\n",
    "dataset_env_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(dataset_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokenized strings on train dataset is : 81\n",
      "Number of tokenized strings on validation dataset is : 27\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset_env       =   dataset_env_split.map( tokenize )\n",
    "# lengths                     =   [len(x['input_ids']) for x in list(tokenized_dataset_env['train']) + list(tokenized_dataset_env['test'])]\n",
    "lengths_train , lengths_validation                     =   [len(x['input_ids']) for x in list(tokenized_dataset_env['train'])] ,[len(x['input_ids']) for x in list(tokenized_dataset_env['test'])]\n",
    "print( f\"Number of tokenized strings on train dataset is : {len(lengths_train)}\")\n",
    "print( f\"Number of tokenized strings on validation dataset is : {len(lengths_validation)}\")\n",
    "fig , (ax1)= plt.subplots( 1 , 1, sharex = False , sharey = False , figsize = (18 , 6) )\n",
    "ax1.hist( lengths_train , bins=50, color='green' , alpha = 0.5 , label='train')\n",
    "ax1.hist( lengths_validation , bins=50, color='red' , alpha = 0.2 , label='validation')\n",
    "ax1.set_xlabel('Length of input_ids')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of lengths of tokens')\n",
    "ax1.legend( loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_name   =   \"shuffle traineval\"\n",
    "training_args   =   TrainingArguments(\n",
    "    output_dir=os.environ['ckpt_dir_crmsc_output'],\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=evalaution_strategy,\n",
    "    eval_steps=eval_steps,\n",
    "    # prediction_loss_only=True, # useless feature\n",
    "    logging_dir=os.environ['ckpt_dir_crmsc_output']+'/runs/'+f\"CRMSC -- {datetime.datetime.now().strftime('%Y-%m-%d %H %M')} -- {specific_name}\",\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "    # auto_find_batch_size=True,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    gradient_checkpointing=gradient_checkpointing,\n",
    "    eval_accumulation_steps=eval_accumulation_steps,\n",
    "    eval_delay=eval_delay,\n",
    "    weight_decay=weight_decay,\n",
    "    optim=optim,\n",
    "    save_strategy=saving_strategy,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    # max_steps=max_steps,\n",
    "    # warmup_ratio=warmup_ratio,\n",
    "    warmup_steps=warmup_steps,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=['tensorboard'],\n",
    "    save_total_limit=4,\n",
    "    disable_tqdm=False,\n",
    "    load_best_model_at_end=load_best_model_at_end,\n",
    "    metric_for_best_model=metric_for_best_model,\n",
    "    save_only_model=True,\n",
    "    greater_is_better=greater_is_better,\n",
    "    run_name= f\"CRMSC -- {datetime.datetime.now().strftime('%Y-%m-%d %H %M')}\"\n",
    ")\n",
    "\n",
    "trainer     =   SFTTrainer(\n",
    "    model=peftmodel, # this is tricky, and we need to change to model later ( there is an issue with CUDA and seems bug come from transformers or dataset cannot be uploaded to cuda)\n",
    "    train_dataset=dataset_env_split['train'],\n",
    "    eval_dataset=dataset_env_split['test'], # Validation is the correct one but we use this key \n",
    "    # peft_config=peft_config,\n",
    "    dataset_text_field='text',\n",
    "    max_seq_length=max_seq_length, # Default is 1024 for COnstantLengthDataset, but we set it as None\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    packing=packing,\n",
    "    data_collator=DataCollatorForLanguageModeling( tokenizer=tokenizer , mlm=False, return_tensors='pt')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.train() # delete the output for better reading :D ( evaluation is controlled via tensorboard )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainOutput(global_step=540, training_loss=0.10287681890962025, metrics={'train_runtime': 1511.2016, 'train_samples_per_second': 1.072, 'train_steps_per_second': 0.357, 'train_loss': 0.10287681890962025, 'epoch': 20.0})\n"
     ]
    }
   ],
   "source": [
    "print( results )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(os.environ['ckpt_dir_crmsc_output'])\n",
    "peftmodel.save_pretrained(os.environ['ckpt_dir_crmsc_output'] + \"\\\\peftmodel\")\n",
    "# trainer.tokenizer.save_pretrained(os.environ['ckpt_dir_crmsc_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# del tokenizer\n",
    "# del trainer\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.reset_max_memory_cached()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
